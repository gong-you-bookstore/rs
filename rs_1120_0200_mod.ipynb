{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "faiss.__version__"
      ],
      "metadata": {
        "id": "0BNExUNGSSau",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15a873b0-8e6e-453d-c1bf-49a643b7bca6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.7.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install faiss-gpu 는 requirements.txt 에 포함된다면 가능"
      ],
      "metadata": {
        "id": "LaQPLsv1WOIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-gpu"
      ],
      "metadata": {
        "id": "zTrFfCjb1Bhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import literal_eval\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from scipy.sparse import csr_matrix\n",
        "import faiss\n",
        "import random\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "books = pd.read_csv('/content/drive/MyDrive/nlbooks.csv', encoding='utf-8')\n",
        "books = books.replace({np.nan: 'none'})\n",
        "\n",
        "# 데이터프레임이 content, thumbnail column을 포함한다면\n",
        "# books_df=books[['isbn13','title','author','publisher','price','img_url','description','kdc_class_no']]\n",
        "books_df=books[['isbn13','title','author','publisher','price','img_url','description','kdc_class_no']]\n",
        "\n",
        "#books_df[['description']=='none']=None\n",
        "books_df_nax=books_df.dropna(axis='rows')\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "# fit_transform안에 데이터프레임형태로 넣어주면 안됨. 하나의 변수씩만 넣어주자!\n",
        "# title_vect1 = cnt_vect.fit_transform(books_df_nax['title'])\n",
        "title_vect2 = tfidf.fit_transform(books_df_nax['title'])\n",
        "#des_vect = cnt_vect.fit_transform(books['description'])\n",
        "#books['book_info']=books['title']+books['description']\n",
        "#b_category=books['kdc_class_no']\n",
        "\n",
        "# 차원 축소 part 를 줄여야 함 -> 파일을 새로 저장해야할듯!\n",
        "X = title_vect2\n",
        "svd = TruncatedSVD(n_components=500, n_iter=7, random_state=42)\n",
        "X_new=svd.fit_transform(X)\n",
        "\n",
        "D = X_new.shape[1]\n",
        "K = 500  # The number of clusters\n",
        "X = X_new.astype(np.float32)\n",
        "\n",
        "# Setup\n",
        "kmeans = faiss.Kmeans(d=D, k=K, niter=20, verbose=True,gpu=True)\n",
        "# For GPU(s), run the following line. This will use all GPUs\n",
        "# kmeans = faiss.Kmeans(d=D, k=K, niter=20, verbose=True, gpu=True)\n",
        "\n",
        "# Run clustering\n",
        "kmeans.train(X)\n",
        "\n",
        "# Error for each iteration\n",
        "# print(kmeans.obj)  # array with 20 elements\n",
        "\n",
        "# Centroids after clustering\n",
        "# print(kmeans.centroids.shape)  # (10, 500)\n",
        "\n",
        "# The assignment for each vector.\n",
        "dists, ids = kmeans.index.search(X, 1)  # Need to run NN search again\n",
        "books_df_nax['tit_cluster']=ids\n",
        "\n",
        "\n",
        "def find_sim_books(U):\n",
        "    def userbooks(A):\n",
        "        l=len(A)\n",
        "        n=random.randrange(0,l)\n",
        "        return A[n]\n",
        "\n",
        "    # 사용자의 isbn 데이터를 담은 책 리스트를 input으로 받아 그 리스트 중 하나를 반환하는 함수\n",
        "    # B = 사용자 데이터에서 랜덤 추출한 책의 isbn \n",
        "    B=userbooks(U)\n",
        "\n",
        "\n",
        "    def sim_idx_with_A(df,isbn):\n",
        "        n=int(df[df['isbn13']==isbn]['tit_cluster'])\n",
        "        same_clu_books_df=df[df['tit_cluster']==n]\n",
        "        sen = same_clu_books_df['description']\n",
        "\n",
        "        # 1번 후보 : sentence transformer 유사도 구하기\n",
        "        #from sentence_transformers import SentenceTransformer\n",
        "        #model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        #sen_embeddings = model.encode(sen)\n",
        "    \n",
        "        # 2번 후보 : 단순 tfidf 활용한 유사도 구하기\n",
        "        clu_tfidf = tfidf.fit_transform(sen)\n",
        "        clu_des_sim=cosine_similarity(clu_tfidf,clu_tfidf)\n",
        "\n",
        "        # idx_list=same_clu_books_df.index[same_clu_books_df['title']==books].tolist()\n",
        "        idx=np.where(same_clu_books_df['isbn13']==B)[0][0]\n",
        "        books_sim_vect=clu_des_sim[idx:idx+1]\n",
        "        books_des_sim_idx = books_sim_vect.argsort()[::-1]\n",
        "\n",
        "        return books_des_sim_idx\n",
        "\n",
        "    # 사용자 책 리스트에서 랜덤 추출한 책 기준 유사한 책 인덱스 리스트 반환\n",
        "    sim_books_idx=sim_idx_with_A(books_df_nax,B)\n",
        "\n",
        "    #books=userbooks(A)\n",
        "    #n=int(df[df['title']==books]['tit_cluster'])\n",
        "    #same_clu_books_df=df[df['tit_cluster']==n]\n",
        "    #sen = same_clu_books_df['description']\n",
        "    top_n=20\n",
        "    top_sim_idx=sim_books_idx[0][:top_n]\n",
        "    top_sim_idx=top_sim_idx.reshape(-1,)\n",
        "\n",
        "    sim_books=books_df_nax.iloc[top_sim_idx]\n",
        "    # 데이터프레임이 content, thumbnail column을 포함한다면\n",
        "    # outputs=sim_books[['title','author','content','thumbnail','publisher','kdc','price']]\n",
        "    outputs=sim_books[['title','author','img_url','publisher','kdc_class_no','price']]\n",
        "    outputs_dic=outputs.to_dict('records')\n",
        "\n",
        "    return outputs_dic"
      ],
      "metadata": {
        "id": "7ioOLOyEvDa8"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xwy3Mqot1nCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력 확인 예시"
      ],
      "metadata": {
        "id": "PZHTaWT-1nFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=books_df_nax.to_dict('records')"
      ],
      "metadata": {
        "id": "yYCJSW5wHAWG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b[0:3]"
      ],
      "metadata": {
        "id": "CgVeJvxXOAVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d18f569a-c108-4c40-c8e9-6708f76848cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'isbn13': 9790000000000.0,\n",
              "  'title': '너에게 목소리를 보낼게 - &lt;달빛천사&gt; 성우 이용신의 첫 번째 에세이',\n",
              "  'author': '이용신 (지은이)',\n",
              "  'publisher': '푸른숲',\n",
              "  'price': 16000.0,\n",
              "  'description': '2004년 방영한 애니메이션 &lt;달빛천사&gt;에서 주인공 루나(풀문) 역을 맡으며 90년대생들에게 보석 같은 추억을 선물한 성우 이용신의 첫 번째 에세이. 수많은 작품의 주연을 맡으며 쉬지 않고 대중에게 행복을 전해온 성우 이용신의 발자취를 확인할 수 있다.',\n",
              "  'kdc_class_no': 'none'},\n",
              " {'isbn13': 9790000000000.0,\n",
              "  'title': '일기에도 거짓말을 쓰는 사람 - 99년생 시인의 자의식 과잉 에세이',\n",
              "  'author': '차도하 (지은이)',\n",
              "  'publisher': '위즈덤하우스',\n",
              "  'price': 15800.0,\n",
              "  'description': '“그러니 나는 말하고 싶은 것을 말하겠다”「침착하게 사랑하기」 차도하 시인 첫 에세이새롭고 도발적인 작품성으로 문단의 기대주로 떠오른 차도하 시인의 첫 번째 산문집이 출간됐다. 혼자 보는 일기에도 거짓말을 쓸 수밖에 없었던 시인의 산문집 『일기에도 거짓말을 쓰는 사람』은 공교롭게도 보는...',\n",
              "  'kdc_class_no': 'none'},\n",
              " {'isbn13': 9790000000000.0,\n",
              "  'title': '본격 한중일 세계사 12 - 임오군란과 통킹 위기',\n",
              "  'author': '굽시니스트 (지은이)',\n",
              "  'publisher': '위즈덤하우스',\n",
              "  'price': 14800.0,\n",
              "  'description': '한중일 관계의 결정적 분기점인 임오군란의 막전 막후를 다룬다. 러시아의 세력 확장을 경계한 청은 ‘친중·결일·연미’라는 계책을 앞세워 조선에 대한 통제를 강화하고, 이를 그냥 보아 넘길 수 없던 일본은 임오군란을 계기로 마수를 뻗치는데…. 정국 안정화와 근대 문물 도입을 향해 뛰어가는 조선의 앞에 놓인 거대한 장애물을 살펴본다.',\n",
              "  'kdc_class_no': 'none'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}