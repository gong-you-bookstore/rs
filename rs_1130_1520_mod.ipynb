{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MSLETdPVrw32"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.decomposition import TruncatedSVD\n",
        "# from scipy.sparse import csr_matrix\n",
        "# import faiss\n",
        "import random\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "# books = pd.read_csv('/content/drive/MyDrive/nlbooks.csv', encoding='utf-8')\n",
        "# books = books.replace({np.nan: 'none'})\n",
        "books = pd.read_csv('/content/drive/MyDrive/books_mod2', encoding='utf-8')\n",
        "books = books.replace({np.nan: 'none'})\n",
        "\n",
        "# 데이터프레임이 content, thumbnail column을 포함한다면\n",
        "# books_df=books[['isbn13','title','author','publisher','price','img_url','description','kdc_class_no']]\n",
        "# books_df=books[['isbn13','title','author','publisher','price','img_url','description','kdc_class_no']]\n",
        "\n",
        "#books_df[['description']=='none']=None\n",
        "books_df_nax=books.dropna(axis='rows')\n",
        "\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "# fit_transform안에 데이터프레임형태로 넣어주면 안됨. 하나의 변수씩만 넣어주자!\n",
        "# title_vect1 = cnt_vect.fit_transform(books_df_nax['title'])\n",
        "# title_vect2 = tfidf.fit_transform(books_df_nax['title'])\n",
        "#des_vect = cnt_vect.fit_transform(books['description'])\n",
        "#books['book_info']=books['title']+books['description']\n",
        "#b_category=books['kdc_class_no']\n",
        "\n",
        "# 차원 축소 part 를 줄여야 함 -> 파일을 새로 저장해야할듯!\n",
        "#X = title_vect2\n",
        "#svd = TruncatedSVD(n_components=500, n_iter=7, random_state=42)\n",
        "#X_new=svd.fit_transform(X)\n",
        "\n",
        "#D = X_new.shape[1]\n",
        "#K = 500  # The number of clusters\n",
        "#X = X_new.astype(np.float32)\n",
        "\n",
        "# Setup\n",
        "#kmeans = faiss.Kmeans(d=D, k=K, niter=20, verbose=True,gpu=True)\n",
        "# For GPU(s), run the following line. This will use all GPUs\n",
        "# kmeans = faiss.Kmeans(d=D, k=K, niter=20, verbose=True, gpu=True)\n",
        "\n",
        "# Run clustering\n",
        "#kmeans.train(X)\n",
        "\n",
        "# Error for each iteration\n",
        "# print(kmeans.obj)  # array with 20 elements\n",
        "\n",
        "# Centroids after clustering\n",
        "# print(kmeans.centroids.shape)  # (10, 500)\n",
        "\n",
        "# The assignment for each vector.\n",
        "#dists, ids = kmeans.index.search(X, 1)  # Need to run NN search again\n",
        "\n",
        "\n",
        "#books_df_nax['tit_cluster']=ids\n",
        "\n",
        "#books_df_nax\n",
        "\n",
        "def find_sim_books(U):\n",
        "    def userbooks(A):\n",
        "        x=books_df_nax['isbn'].tolist()\n",
        "        l=len(A)\n",
        "        BD=[]\n",
        "        for i in range(l):\n",
        "            if A[i] in x:\n",
        "              BD.append(A[i])\n",
        "        l2=len(BD)\n",
        "        n=random.randrange(0,l2)\n",
        "        return BD[n]\n",
        "\n",
        "    # 사용자의 isbn 데이터를 담은 책 리스트를 input으로 받아 그 리스트 중 하나를 반환하는 함수\n",
        "    # B = 사용자 데이터에서 랜덤 추출한 책의 isbn \n",
        "    B=userbooks(U) \n",
        "\n",
        "\n",
        "    def sim_idx_with_A(df,isbn):\n",
        "        n=int(df[df['isbn']==isbn]['tit_cluster'])\n",
        "        same_clu_books_df=df[df['tit_cluster']==n]\n",
        "        sen = same_clu_books_df['content']\n",
        "\n",
        "        # 1번 후보 : sentence transformer 유사도 구하기\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        sen_embeddings = model.encode(sen)\n",
        "        clu_des_sim=cosine_similarity(sen_embeddings,sen_embeddings)\n",
        "    \n",
        "        # 2번 후보 : 단순 tfidf 활용한 유사도 구하기\n",
        "        # clu_tfidf = tfidf.fit_transform(sen)\n",
        "        # clu_des_sim=cosine_similarity(clu_tfidf,clu_tfidf)\n",
        "\n",
        "        # idx_list=same_clu_books_df.index[same_clu_books_df['title']==books].tolist()\n",
        "        idx=np.where(same_clu_books_df['isbn']==B)[0][0]\n",
        "        books_sim_vect=clu_des_sim[idx:idx+1]\n",
        "        books_des_sim_idx = books_sim_vect.argsort()[::-1]\n",
        "\n",
        "        return books_des_sim_idx\n",
        "\n",
        "    # 사용자 책 리스트에서 랜덤 추출한 책 기준 유사한 책 인덱스 리스트 반환\n",
        "    sim_books_idx=sim_idx_with_A(books_df_nax,B)\n",
        "\n",
        "    #books=userbooks(A)\n",
        "    #n=int(df[df['title']==books]['tit_cluster'])\n",
        "    #same_clu_books_df=df[df['tit_cluster']==n]\n",
        "    #sen = same_clu_books_df['description']\n",
        "    top_n=20\n",
        "    top_sim_idx=sim_books_idx[0][:top_n]\n",
        "    top_sim_idx=top_sim_idx.reshape(-1,)\n",
        "\n",
        "    sim_books=books_df_nax.iloc[top_sim_idx]\n",
        "    # 데이터프레임이 content, thumbnail column을 포함한다면\n",
        "    outputs=sim_books[['isbn','title','author','content','thumbnail','publisher','kdc','price']]\n",
        "    # outputs=sim_books[['title','author','img_url','publisher','kdc_class_no','price']]\n",
        "    outputs_dic=outputs.to_dict('records')\n",
        "\n",
        "    return outputs_dic"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2FrY1d0hr4IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-2c-uDQt8DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hlx4_1_Bvfl6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}